{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conditional Generative Adversaril Network Training script</h1>\n",
    "\n",
    "<p>This script provides the basis to train the model that will generate the patches from the original image. The process of generating new patches is fueled by the segmentation of original images to increase the available data volume. Once the trained model is ready the inference will provide new patches for the images that will flow through the whole L.E.G.O. Net Pipeline</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
    "\n",
    "# Configurations\n",
    "batch_size = 64\n",
    "num_channels = 3  # RGB \n",
    "num_classes = 2\n",
    "image_size = (64, 64)  \n",
    "latent_dim = 128\n",
    "\n",
    "# Paths to data\n",
    "patch_dir = '../LEGO/data/patches/'  # Directory containing patch images\n",
    "csv_path = '../LEGO/data/csv/patch_metadata.csv'  # Path to CSV file with metadata\n",
    "\n",
    "# Start time tracking\n",
    "start_time = time.time()\n",
    "\n",
    "# Load metadata\n",
    "print(\"Loading metadata...\")\n",
    "metadata = pd.read_csv(csv_path)\n",
    "print(f\"Metadata loaded. {metadata.shape[0]} entries found.\")\n",
    "print(f\"Time taken to load metadata: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Encode labels to integers then to one-hot\n",
    "print(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(metadata['class'])\n",
    "one_hot_labels = to_categorical(integer_encoded, num_classes=num_classes)\n",
    "print(f\"Labels encoded. Number of classes: {num_classes}\")\n",
    "print(f\"Time taken to encode labels: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Function to get the full path of the patch\n",
    "def get_patch_path(row):\n",
    "    patch_filename = f\"{row['patch_id']}.png\"\n",
    "    return os.path.join(patch_dir, patch_filename)\n",
    "\n",
    "# Load and process patch images\n",
    "def process_patch(patch_path):\n",
    "    img = load_img(patch_path, target_size=image_size, color_mode='rgb')\n",
    "    img_array = img_to_array(img).astype(\"float32\") / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Load all patches and corresponding labels\n",
    "print(\"Loading and processing patches...\")\n",
    "patch_paths = [get_patch_path(row) for _, row in metadata.iterrows()]\n",
    "patches = np.array([process_patch(patch_path) for patch_path in patch_paths if os.path.exists(patch_path)])\n",
    "labels = one_hot_labels[:len(patches)]  # Align labels with loaded patches\n",
    "print(f\"Patches loaded and processed. {len(patches)} patches found.\")\n",
    "print(f\"Time taken to load patches: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Ensure the images have 4 dimensions (batch_size, height, width, channels)\n",
    "patches = np.reshape(patches, (-1, image_size[0], image_size[1], num_channels))\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "print(\"Creating TensorFlow dataset...\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((patches, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "print(f\"Dataset created with batch size {batch_size}.\")\n",
    "print(f\"Time taken to create dataset: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print data shapes for confirmation\n",
    "print(f\"Shape of patches: {patches.shape}\")\n",
    "print(f\"Shape of labels: {labels.shape}\")\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "print(f\"Generator input channels: {generator_in_channels}\")\n",
    "print(f\"Discriminator input channels: {discriminator_in_channels}\")\n",
    "\n",
    "# Create the discriminator with added dropout and input noise\n",
    "print(\"Building discriminator...\")\n",
    "discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer((image_size[0], image_size[1], discriminator_in_channels)),\n",
    "        layers.GaussianNoise(0.3),  # Adding noise to the inputs\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),  # Changed negative_slope to alpha (Library Update)\n",
    "        layers.Dropout(0.3),  # Adding dropout to prevent overfitting\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),  # Changed negative_slope to alpha\n",
    "        layers.Dropout(0.3),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "print(\"Discriminator built.\")\n",
    "print(f\"Time taken to build discriminator: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Create the generator with an additional layer to enhance capacity\n",
    "print(\"Building generator...\")\n",
    "generator = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense((image_size[0] // 4) * (image_size[1] // 4) * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),  \n",
    "        layers.Reshape((image_size[0] // 4, image_size[1] // 4, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),  \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),  \n",
    "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),  # Additional layer\n",
    "        layers.LeakyReLU(alpha=0.2),  \n",
    "        layers.Conv2D(num_channels, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "print(\"Generator built.\")\n",
    "print(f\"Time taken to build generator: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "class ConditionalGAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, one_hot_labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # Ensure one_hot_labels is float32\n",
    "        one_hot_labels = tf.cast(one_hot_labels, tf.float32)\n",
    "\n",
    "        # Expand labels to match the shape of images for concatenation\n",
    "        image_one_hot_labels = tf.reshape(one_hot_labels, (-1, 1, 1, num_classes))\n",
    "        image_one_hot_labels = tf.tile(image_one_hot_labels, [1, image_size[0], image_size[1], 1])\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Ensure generated images have the same size as real images\n",
    "        generated_images = tf.image.resize(generated_images, image_size)\n",
    "\n",
    "        # Combine them with real images\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], axis=-1)\n",
    "        real_image_and_labels = tf.concat([tf.cast(real_images, tf.float32), image_one_hot_labels], axis=-1)\n",
    "        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_images = tf.image.resize(fake_images, image_size)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], axis=-1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        # Print the current loss values for generator and discriminator\n",
    "        tf.print(\"Generator loss:\", self.gen_loss_tracker.result())\n",
    "        tf.print(\"Discriminator loss:\", self.disc_loss_tracker.result())\n",
    "\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'latent_dim': self.latent_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        latent_dim = config['latent_dim']\n",
    "        discriminator = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer((image_size[0], image_size[1], discriminator_in_channels)),\n",
    "                layers.GaussianNoise(0.1),\n",
    "                layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),  \n",
    "                layers.Dropout(0.3),\n",
    "                layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),  \n",
    "                layers.Dropout(0.3),\n",
    "                layers.GlobalMaxPooling2D(),\n",
    "                layers.Dense(1),\n",
    "            ],\n",
    "            name=\"discriminator\",\n",
    "        )\n",
    "\n",
    "        generator = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.InputLayer((latent_dim + num_classes,)),\n",
    "                layers.Dense((image_size[0] // 4) * (image_size[1] // 4) * 128),\n",
    "                layers.LeakyReLU(alpha=0.2), \n",
    "                layers.Reshape((image_size[0] // 4, image_size[1] // 4, 128)),\n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),  \n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),  \n",
    "                layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(alpha=0.2),  \n",
    "                layers.Conv2D(num_channels, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "            ],\n",
    "            name=\"generator\",\n",
    "        )\n",
    "        return cls(discriminator, generator, latent_dim)\n",
    "\n",
    "    def save(self, filepath, overwrite=True, include_optimizer=True):\n",
    "        config = {\n",
    "            'class_name': self.__class__.__name__,\n",
    "            'config': self.get_config()\n",
    "        }\n",
    "        with open(filepath + '_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        self.generator.save_weights(filepath + '_generator.weights.h5', overwrite=overwrite)\n",
    "        self.discriminator.save_weights(filepath + '_discriminator.weights.h5', overwrite=overwrite)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        with open(filepath + '_config.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        model = cls.from_config(config['config'])\n",
    "        model.generator.load_weights(filepath + '_generator.weights.h5')\n",
    "        model.discriminator.load_weights(filepath + '_discriminator.weights.h5')\n",
    "        return model\n",
    "\n",
    "# Instantiate and compile the ConditionalGAN model\n",
    "print(\"Initializing Conditional GAN...\")\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "print(\"Conditional GAN initialized.\")\n",
    "print(f\"Time taken to initialize GAN: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Lists to store loss values for plotting\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "# Custom training loop to capture losses\n",
    "for epoch in range(3):  # Replace 3 with desired number of epochs\n",
    "    print(f\"Epoch {epoch + 1}/{3}\")  # Update to reflect the correct number of epochs\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(dataset):\n",
    "        loss = cond_gan.train_step((x_batch_train, y_batch_train))\n",
    "        g_losses.append(loss['g_loss'].numpy())\n",
    "        d_losses.append(loss['d_loss'].numpy())\n",
    "    print(f\"Epoch {epoch + 1} completed. Generator loss: {loss['g_loss']}, Discriminator loss: {loss['d_loss']}\")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(f\"Total time taken for training: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Plotting the loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses for Generator and Discriminator')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "print(\"Saving the model...\")\n",
    "cond_gan.save('cond_gan_model')\n",
    "print(\"Model saved.\")\n",
    "print(f\"Time taken to save the model: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Load the model for verification\n",
    "print(\"Loading the model for verification...\")\n",
    "loaded_model = ConditionalGAN.load('cond_gan_model')\n",
    "print(\"Model loaded.\")\n",
    "print(f\"Time taken to load the model: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Recompile the model after loading\n",
    "print(\"Recompiling the loaded model...\")\n",
    "loaded_model.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "print(\"Model recompiled.\")\n",
    "print(f\"Time taken to recompile the model: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Build the discriminator by specifying input shape\n",
    "loaded_model.discriminator.build(input_shape=(None, image_size[0], image_size[1], discriminator_in_channels))\n",
    "\n",
    "# Verify the model structure\n",
    "print(\"Discriminator summary:\")\n",
    "loaded_model.discriminator.summary()\n",
    "\n",
    "# Build the generator by specifying input shape\n",
    "loaded_model.generator.build(input_shape=(None, latent_dim + num_classes))\n",
    "\n",
    "# Verify the generator structure\n",
    "print(\"Generator summary:\")\n",
    "loaded_model.generator.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
