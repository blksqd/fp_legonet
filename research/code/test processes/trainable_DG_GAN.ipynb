{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This implementation of the DCGAN has been inspired and modified from the example provided here:\n",
    "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb\n",
    "Adjusted have been made to adapt to the different dataset and to accept a different format condiering that\n",
    "the melanoma patches need to be generated with positional information within the image group.\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "# Directory path for melanoma patches\n",
    "melanoma_dir = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/Images/img_patches/mel_patches'\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [64, 64])\n",
    "    image = (image - 0.5) * 2  # Normalize to [-1, 1]\n",
    "    return image\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 32  \n",
    "\n",
    "# Load melanoma patches\n",
    "melanoma_paths = [os.path.join(melanoma_dir, fname) for fname in os.listdir(melanoma_dir)]\n",
    "melanoma_dataset = tf.data.Dataset.from_tensor_slices(melanoma_paths)\n",
    "melanoma_dataset = melanoma_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "melanoma_dataset = melanoma_dataset.shuffle(buffer_size=len(melanoma_paths)).batch(batch_size)\n",
    "\n",
    "# Define the generator model\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(100,)))\n",
    "    model.add(layers.Dense(16*16*256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((16, 16, 256)))\n",
    "    assert model.output_shape == (None, 16, 16, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 32, 32, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 64, 64, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 64, 64, 3)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(64, 64, 3)))\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "EPOCHS = 500\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# Lists to keep track of the losses\n",
    "gen_losses = []\n",
    "disc_losses = []\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "def train(dataset, epochs, save_interval=50):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_gen_loss = 0\n",
    "        epoch_disc_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            epoch_gen_loss += gen_loss\n",
    "            epoch_disc_loss += disc_loss\n",
    "            num_batches += 1\n",
    "\n",
    "        # Average the losses over all batches\n",
    "        epoch_gen_loss /= num_batches\n",
    "        epoch_disc_loss /= num_batches\n",
    "\n",
    "        gen_losses.append(epoch_gen_loss)\n",
    "        disc_losses.append(epoch_disc_loss)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        print(f\"Time for epoch {epoch + 1} is {time.time()-start} sec\")\n",
    "        print(f\"Generator loss: {epoch_gen_loss.numpy()}, Discriminator loss: {epoch_disc_loss.numpy()}\")\n",
    "\n",
    "        # Plot the losses\n",
    "        plot_losses(gen_losses, disc_losses)\n",
    "\n",
    "        # Save the model at regular intervals\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            save_models(generator, discriminator, epoch + 1)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)\n",
    "\n",
    "def save_models(generator, discriminator, epoch):\n",
    "    generator.save(f'generator_epoch_{epoch}.h5')\n",
    "    discriminator.save(f'discriminator_epoch_{epoch}.h5')\n",
    "    print(f'Models saved at epoch {epoch}')\n",
    "\n",
    "def plot_losses(gen_losses, disc_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(gen_losses, label='Generator Loss')\n",
    "    plt.plot(disc_losses, label='Discriminator Loss')\n",
    "    plt.title('Generator and Discriminator Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :] + 1) / 2)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "# Train the model to generate melanoma patches\n",
    "train(melanoma_dataset, EPOCHS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
