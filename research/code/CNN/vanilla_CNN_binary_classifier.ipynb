{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Using cached scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (53 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl (28.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid paths: 0\n",
      "Found 2831 validated image filenames belonging to 2 classes.\n",
      "Found 708 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Define the paths\n",
    "base_dir = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2'\n",
    "csv_path = os.path.join(base_dir, 'csv_files', 'patches_with_labels.csv')\n",
    "img_dir = os.path.join(base_dir, 'Images', 'img_patches')\n",
    "model_save_path = os.path.join(base_dir, 'models', 'skin_lesion_model.keras')\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to extract patch number from Patch_id\n",
    "def get_patch_folder(patch_id):\n",
    "    parts = patch_id.split('_')\n",
    "    patch_num = parts[-1].split('.')[0]  # Extract patch number\n",
    "    return f'Patch_{patch_num}'\n",
    "\n",
    "# Add a full path to each patch\n",
    "def get_full_path(row):\n",
    "    try:\n",
    "        patch_folder = get_patch_folder(row['Patch_id'])\n",
    "        if row['label'] == 1:\n",
    "            return os.path.join(img_dir, 'mel_patches', patch_folder, row['Patch_id'])\n",
    "        else:\n",
    "            return os.path.join(img_dir, 'bkl_patches', patch_folder, row['Patch_id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "data['path'] = data.apply(get_full_path, axis=1)\n",
    "\n",
    "# Check for invalid paths and remove them\n",
    "invalid_paths = data[~data['path'].apply(os.path.exists)]\n",
    "print(f\"Number of invalid paths: {len(invalid_paths)}\")\n",
    "if not invalid_paths.empty:\n",
    "    print(invalid_paths.head())\n",
    "    data = data[data['path'].apply(os.path.exists)]\n",
    "\n",
    "# Convert label column to string\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=42)\n",
    "\n",
    "# Use only 10% of the data for testing\n",
    "train_data = train_data.sample(frac=0.1, random_state=42)\n",
    "val_data = val_data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Image data generator for augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create training and validation generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_accuracy'),\n",
    "    EarlyStopping(patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define a function to pool predictions from the 16 patches to produce a final prediction for the full image\n",
    "def predict_full_image(image_id, model, data):\n",
    "    patches = data[data['image_id'] == image_id]['path'].values\n",
    "    predictions = []\n",
    "\n",
    "    for patch in patches:\n",
    "        img = load_img(patch, target_size=(64, 64))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        prediction = model.predict(img_array, verbose=0)\n",
    "        predictions.append(prediction[0][0])\n",
    "\n",
    "    return np.mean(predictions)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_predictions = []\n",
    "val_labels = []\n",
    "\n",
    "for image_id in tqdm(val_data['image_id'].unique(), desc='Evaluating images'):\n",
    "    label = val_data[val_data['image_id'] == image_id]['label'].values[0]\n",
    "    val_labels.append(int(label))\n",
    "    final_prediction = predict_full_image(image_id, model, val_data)\n",
    "    val_predictions.append(final_prediction)\n",
    "\n",
    "# Convert predictions to binary class (0 or 1)\n",
    "val_predictions_binary = [1 if pred >= 0.5 else 0 for pred in val_predictions]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(np.array(val_predictions_binary) == np.array(val_labels))\n",
    "print('Validation accuracy:', accuracy)\n",
    "\n",
    "# Example usage for a single image prediction\n",
    "image_id = 'ISIC_0028965'\n",
    "final_prediction = predict_full_image(image_id, model, data)\n",
    "print(f'Final prediction for image {image_id}:', final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
