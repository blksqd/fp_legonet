{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35790 images belonging to 2 classes.\n",
      "Found 8946 images belonging to 2 classes.\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |128               |filters_32\n",
      "224               |224               |filters_64\n",
      "224               |224               |filters_128\n",
      "160               |160               |filters_256\n",
      "896               |896               |units_512\n",
      "0.6               |0.6               |dropout_rate\n",
      "0.0002242         |0.0002242         |learning_rate\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 255ms/step - accuracy: 0.5669 - loss: 1.4007 - val_accuracy: 0.6037 - val_loss: 1.0666 - learning_rate: 2.2420e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 252ms/step - accuracy: 0.5882 - loss: 1.0843 - val_accuracy: 0.6394 - val_loss: 0.9103 - learning_rate: 2.2420e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 241ms/step - accuracy: 0.6028 - loss: 0.9140 - val_accuracy: 0.6527 - val_loss: 0.7665 - learning_rate: 2.2420e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 242ms/step - accuracy: 0.6104 - loss: 0.7724 - val_accuracy: 0.6226 - val_loss: 0.7142 - learning_rate: 2.2420e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 253ms/step - accuracy: 0.6192 - loss: 0.6878 - val_accuracy: 0.6311 - val_loss: 0.6383 - learning_rate: 2.2420e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 263ms/step - accuracy: 0.6187 - loss: 0.6554 - val_accuracy: 0.6273 - val_loss: 0.6399 - learning_rate: 2.2420e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 271ms/step - accuracy: 0.6223 - loss: 0.6371 - val_accuracy: 0.6283 - val_loss: 0.6208 - learning_rate: 2.2420e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 269ms/step - accuracy: 0.6275 - loss: 0.6308 - val_accuracy: 0.6422 - val_loss: 0.6207 - learning_rate: 2.2420e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 269ms/step - accuracy: 0.6289 - loss: 0.6309 - val_accuracy: 0.6321 - val_loss: 0.6313 - learning_rate: 2.2420e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 270ms/step - accuracy: 0.6196 - loss: 0.6362 - val_accuracy: 0.6272 - val_loss: 0.6545 - learning_rate: 2.2420e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 270ms/step - accuracy: 0.6214 - loss: 0.6330 - val_accuracy: 0.6258 - val_loss: 0.6244 - learning_rate: 2.2420e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 270ms/step - accuracy: 0.6188 - loss: 0.6301 - val_accuracy: 0.6473 - val_loss: 0.6166 - learning_rate: 2.2420e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 269ms/step - accuracy: 0.6291 - loss: 0.6281 - val_accuracy: 0.6389 - val_loss: 0.6123 - learning_rate: 2.2420e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 271ms/step - accuracy: 0.6282 - loss: 0.6304 - val_accuracy: 0.6468 - val_loss: 0.6064 - learning_rate: 2.2420e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 270ms/step - accuracy: 0.6276 - loss: 0.6280 - val_accuracy: 0.6461 - val_loss: 0.6086 - learning_rate: 2.2420e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 270ms/step - accuracy: 0.6256 - loss: 0.6262 - val_accuracy: 0.6097 - val_loss: 0.6827 - learning_rate: 2.2420e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1119/1119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 270ms/step - accuracy: 0.6302 - loss: 0.6251 - val_accuracy: 0.6465 - val_loss: 0.6079 - learning_rate: 2.2420e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m 147/1119\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 255ms/step - accuracy: 0.6085 - loss: 0.6365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m ReduceLROnPlateau(factor\u001b[39m=\u001b[39mreduce_lr_factor, patience\u001b[39m=\u001b[39mreduce_lr_patience, min_lr\u001b[39m=\u001b[39mmin_lr)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m# Run the tuner\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     train_generator,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, reduce_lr]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/colab_binary_RestNet50_keras_tuner.ipynb#W0sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m best_hps \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[39m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the configuration file\n",
    "with open('/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/config_v8_cnn.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Paths\n",
    "base_dir = config['paths']['base_dir']\n",
    "csv_path = config['paths']['csv_path']\n",
    "img_dir = config['paths']['img_dir']\n",
    "model_save_path = config['paths']['model_save_path']\n",
    "\n",
    "# Training parameters\n",
    "validation_split = config['training']['validation_split']\n",
    "fraction = config['training']['fraction']\n",
    "batch_size = config['training']['batch_size']\n",
    "epochs = config['training']['epochs']\n",
    "initial_learning_rate = config['training']['initial_learning_rate']\n",
    "learning_rate_decay = config['training']['learning_rate_decay']\n",
    "patience = config['training']['patience']\n",
    "reduce_lr_factor = config['training']['reduce_lr_factor']\n",
    "reduce_lr_patience = config['training']['reduce_lr_patience']\n",
    "min_lr = config['training']['min_lr']\n",
    "\n",
    "# Data augmentation parameters\n",
    "data_aug_params = config['data_augmentation']\n",
    "\n",
    "# Model architecture parameters\n",
    "input_shape = tuple(config['model_architecture']['input_shape'])\n",
    "conv_layers = config['model_architecture']['conv_layers']\n",
    "pool_size = tuple(config['model_architecture']['pool_size'])\n",
    "dense_layers = config['model_architecture']['dense_layers']\n",
    "dropout_rate = config['model_architecture']['dropout_rate']\n",
    "batch_normalization = config['model_architecture']['batch_normalization']\n",
    "l2_regularization = config['model_architecture']['l2_regularization']\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=data_aug_params['rescale'],\n",
    "    rotation_range=data_aug_params['rotation_range'],\n",
    "    width_shift_range=data_aug_params['width_shift_range'],\n",
    "    height_shift_range=data_aug_params['height_shift_range'],\n",
    "    shear_range=data_aug_params['shear_range'],\n",
    "    zoom_range=data_aug_params['zoom_range'],\n",
    "    horizontal_flip=data_aug_params['horizontal_flip'],\n",
    "    vertical_flip=data_aug_params['vertical_flip'],\n",
    "    brightness_range=data_aug_params['brightness_range'],\n",
    "    validation_split=validation_split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=input_shape))\n",
    "        for layer in conv_layers:\n",
    "            model.add(Conv2D(\n",
    "                filters=hp.Int('filters_' + str(layer['filters']), min_value=32, max_value=256, step=32),\n",
    "                kernel_size=tuple(layer['kernel_size']),\n",
    "                activation=layer['activation'],\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)\n",
    "            ))\n",
    "            if batch_normalization:\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=pool_size))\n",
    "        \n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        \n",
    "        for layer in dense_layers:\n",
    "            model.add(Dense(units=hp.Int('units_' + str(layer['units']), min_value=128, max_value=1024, step=128), activation=layer['activation']))\n",
    "            if batch_normalization:\n",
    "                model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=initial_learning_rate)),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Hyperparameter tuner\n",
    "tuner = RandomSearch(\n",
    "    CNNHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory=base_dir,\n",
    "    project_name='skin_lesion_tuning'\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=reduce_lr_factor, patience=reduce_lr_patience, min_lr=min_lr)\n",
    "\n",
    "# Run the tuner\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the best model\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
