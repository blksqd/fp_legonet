{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Your `PyDataset` class should call `super\\.__init__$begin:math:text$\\\\*\\\\*kwargs$end:math:text$`\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='evolutionary_optimization.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "# Load configuration from JSON file\n",
    "config_path = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/CNN/config_v6_86_acc.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    base_config = json.load(f)\n",
    "\n",
    "# Define the hyperparameter space\n",
    "hyperparameter_space = {\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [3, 5, 10],  # Reduced for testing\n",
    "    \"initial_learning_rate\": [0.001, 0.0001, 0.00001],\n",
    "    \"dropout_rate\": [0.3, 0.5, 0.7],\n",
    "    \"rotation_range\": [10, 20, 30],\n",
    "    \"width_shift_range\": [0.1, 0.2, 0.3],\n",
    "    \"height_shift_range\": [0.1, 0.2, 0.3],\n",
    "    \"zoom_range\": [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "def generate_random_hyperparameters():\n",
    "    return {key: random.choice(values) for key, values in hyperparameter_space.items()}\n",
    "\n",
    "def generate_initial_population(size=100):\n",
    "    return [generate_random_hyperparameters() for _ in range(size)]\n",
    "\n",
    "def evaluate_fitness(hyperparameters, train_data, val_data):\n",
    "    print(f\"Evaluating hyperparameters: {hyperparameters}\")\n",
    "    \n",
    "    # Create the data generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=base_config['data_augmentation']['rescale'],\n",
    "        rotation_range=hyperparameters['rotation_range'],\n",
    "        width_shift_range=hyperparameters['width_shift_range'],\n",
    "        height_shift_range=hyperparameters['height_shift_range'],\n",
    "        zoom_range=hyperparameters['zoom_range'],\n",
    "        horizontal_flip=base_config['data_augmentation']['horizontal_flip'],\n",
    "        vertical_flip=base_config['data_augmentation']['vertical_flip'],\n",
    "        brightness_range=base_config['data_augmentation']['brightness_range']\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=base_config['data_augmentation']['rescale'])\n",
    "\n",
    "    # Create training and validation generators\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_data,\n",
    "        x_col='path',\n",
    "        y_col='label',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=hyperparameters['batch_size'],\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_dataframe(\n",
    "        val_data,\n",
    "        x_col='path',\n",
    "        y_col='label',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=hyperparameters['batch_size'],\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    # Define the pre-trained model with ResNet50\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(hyperparameters['dropout_rate']),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=hyperparameters['initial_learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=hyperparameters['epochs'],\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1  # Enable verbose output\n",
    "    )\n",
    "    print(\"Model training completed.\")\n",
    "\n",
    "    val_accuracy = np.max(history.history['val_accuracy'])\n",
    "    return val_accuracy\n",
    "\n",
    "def select_parents(population, fitnesses, num_parents=20):\n",
    "    parents = np.argsort(fitnesses)[-num_parents:]\n",
    "    return [population[p] for p in parents]\n",
    "\n",
    "def crossover(parents, num_offsprings=80):\n",
    "    offsprings = []\n",
    "    for _ in range(num_offsprings):\n",
    "        parent1, parent2 = random.sample(parents, 2)\n",
    "        child = {}\n",
    "        for key in hyperparameter_space.keys():\n",
    "            child[key] = random.choice([parent1[key], parent2[key]])\n",
    "        offsprings.append(child)\n",
    "    return offsprings\n",
    "\n",
    "def mutate(offspring):\n",
    "    for key in hyperparameter_space.keys():\n",
    "        if random.random() < 0.1:  # mutation probability\n",
    "            offspring[key] = random.choice(hyperparameter_space[key])\n",
    "    return offspring\n",
    "\n",
    "def generate_new_population(parents, offsprings):\n",
    "    population = parents + offsprings\n",
    "    return [mutate(offspring) for offspring in population]\n",
    "\n",
    "def evolutionary_optimization(train_data, val_data, generations=2, population_size=10):  # Reduced for testing\n",
    "    population = generate_initial_population(population_size)\n",
    "    fitness_history = []\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        logging.info(f\"Generation {generation+1} started.\")\n",
    "        print(f\"Generation {generation+1}\")\n",
    "        \n",
    "        fitnesses = []\n",
    "        for ind in tqdm(population, desc=f\"Evaluating Generation {generation+1}\", position=0, leave=True):\n",
    "            fitness = evaluate_fitness(ind, train_data, val_data)\n",
    "            fitnesses.append(fitness)\n",
    "        \n",
    "        best_fitness = max(fitnesses)\n",
    "        fitness_history.append(best_fitness)\n",
    "        \n",
    "        logging.info(f\"Generation {generation+1} best fitness: {best_fitness}\")\n",
    "        print(f\"Best fitness: {best_fitness}\")\n",
    "\n",
    "        parents = select_parents(population, fitnesses)\n",
    "        offsprings = crossover(parents)\n",
    "        population = generate_new_population(parents, offsprings)\n",
    "\n",
    "    return population, fitnesses, fitness_history\n",
    "\n",
    "def plot_fitness_history(fitness_history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(fitness_history) + 1), fitness_history, marker='o')\n",
    "    plt.title('Fitness Over Generations')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Best Fitness (Validation Accuracy)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv(base_config['paths']['csv_path'])\n",
    "\n",
    "def get_patch_folder(patch_id):\n",
    "    parts = patch_id.split('_')\n",
    "    patch_num = parts[-1].split('.')[0]\n",
    "    return f'Patch_{patch_num}'\n",
    "\n",
    "def get_full_path(row):\n",
    "    try:\n",
    "        patch_folder = get_patch_folder(row['Patch_id'])\n",
    "        if row['label'] == 1:\n",
    "            full_path = os.path.join(base_config['paths']['img_dir'], 'mel_patches', patch_folder, row['Patch_id'])\n",
    "        else:\n",
    "            full_path = os.path.join(base_config['paths']['img_dir'], 'bkl_patches', patch_folder, row['Patch_id'])\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"Invalid path: {full_path}\")\n",
    "\n",
    "        return full_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "data['path'] = data.apply(get_full_path, axis=1)\n",
    "data['path_exists'] = data['path'].apply(os.path.exists)\n",
    "data = data[data['path_exists']]\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "# Reduce dataset size for testing\n",
    "data = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=base_config['training']['validation_split'], stratify=data['label'], random_state=42)\n",
    "train_data = train_data.sample(frac=base_config['training']['fraction'], random_state=42)\n",
    "val_data = val_data.sample(frac=base_config['training']['fraction'], random_state=42)\n",
    "\n",
    "# Perform evolutionary optimization\n",
    "final_population, final_fitnesses, fitness_history = evolutionary_optimization(train_data, val_data)\n",
    "best_hyperparameters = final_population[np.argmax(final_fitnesses)]\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "\n",
    "# Plot fitness history\n",
    "plot_fitness_history(fitness_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
