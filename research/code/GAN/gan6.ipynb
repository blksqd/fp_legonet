{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (10015, 128, 96, 3)\n",
      "Shape of labels: (10015, 2)\n",
      "Generator input channels: 130\n",
      "Discriminator input channels: 5\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configurations\n",
    "batch_size = 64\n",
    "num_channels = 3  # RGB images have 3 channels\n",
    "num_classes = 2\n",
    "image_size = (128, 96)  # Resize to save memory\n",
    "latent_dim = 128\n",
    "\n",
    "# Paths to data\n",
    "image_dir = '../Data/HAM/ham_images/'  # Directory containing images\n",
    "csv_path = '../Experiments/two_class_metadata.csv'  # Path to CSV file\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract image IDs and classes\n",
    "image_ids = df['image_id'].values\n",
    "labels = df['class'].values\n",
    "\n",
    "# Encode labels to integers then to one-hot\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(integer_encoded, num_classes=num_classes)\n",
    "\n",
    "# Define function to get full image path\n",
    "def get_image_path(image_id):\n",
    "    return f\"{image_dir}/{image_id}.jpg\"  # Assuming images are in .jpg format\n",
    "\n",
    "# Load and process images\n",
    "def process_image(image_id):\n",
    "    full_path = get_image_path(image_id)\n",
    "    img = load_img(full_path, target_size=image_size, color_mode='rgb')  # Load as RGB\n",
    "    img_array = img_to_array(img).astype(\"float32\") / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Create datasets\n",
    "all_images = np.array([process_image(image_id) for image_id in image_ids])\n",
    "all_labels = one_hot_labels\n",
    "\n",
    "# Ensure the images have 4 dimensions (batch_size, height, width, channels)\n",
    "all_images = np.reshape(all_images, (-1, image_size[0], image_size[1], num_channels))\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Print data shapes for confirmation\n",
    "print(f\"Shape of images: {all_images.shape}\")\n",
    "print(f\"Shape of labels: {all_labels.shape}\")\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "print(f\"Generator input channels: {generator_in_channels}\")\n",
    "print(f\"Discriminator input channels: {discriminator_in_channels}\")\n",
    "\n",
    "# Create the discriminator with added dropout and input noise.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((*image_size, discriminator_in_channels)),\n",
    "        layers.GaussianNoise(0.1),  # Adding noise to the inputs\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Dropout(0.3),  # Adding dropout to prevent overfitting\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator with an additional layer to enhance capacity.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense((image_size[0] // 4) * (image_size[1] // 4) * 128),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((image_size[0] // 4, image_size[1] // 4, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),  # Additional layer\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(num_channels, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed = 1337\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, one_hot_labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # Ensure one_hot_labels is float32\n",
    "        one_hot_labels = tf.cast(one_hot_labels, tf.float32)\n",
    "        \n",
    "        # Expand labels to match the shape of images for concatenation.\n",
    "        image_one_hot_labels = tf.reshape(one_hot_labels, (-1, 1, 1, num_classes))\n",
    "        image_one_hot_labels = tf.tile(image_one_hot_labels, [1, image_size[0], image_size[1], 1])\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed)\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Ensure generated images have the same size as real images.\n",
    "        generated_images = tf.image.resize(generated_images, image_size)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], axis=-1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], axis=-1)\n",
    "        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed)\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_images = tf.image.resize(fake_images, image_size)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], axis=-1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'latent_dim': self.latent_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        latent_dim = config['latent_dim']\n",
    "        discriminator = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer((128, 96, 5)),  # Image dimensions + label channels\n",
    "                layers.GaussianNoise(0.1),\n",
    "                layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Dropout(0.3),\n",
    "                layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Dropout(0.3),\n",
    "                layers.GlobalMaxPooling2D(),\n",
    "                layers.Dense(1),\n",
    "            ],\n",
    "            name=\"discriminator\",\n",
    "        )\n",
    "\n",
    "        generator = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.InputLayer((latent_dim + 2,)),  # Latent space dimension + label channels\n",
    "                layers.Dense((128 // 4) * (96 // 4) * 128),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Reshape((128 // 4, 96 // 4, 128)),\n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                layers.LeakyReLU(negative_slope=0.2),\n",
    "                layers.Conv2D(3, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "            ],\n",
    "            name=\"generator\",\n",
    "        )\n",
    "        return cls(discriminator, generator, latent_dim)\n",
    "\n",
    "    def save(self, filepath, overwrite=True, include_optimizer=True):\n",
    "        config = {\n",
    "            'class_name': self.__class__.__name__,\n",
    "            'config': self.get_config()\n",
    "        }\n",
    "        with open(filepath + '_config.json', 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        self.generator.save_weights(filepath + '_generator.weights.h5', overwrite=overwrite)\n",
    "        self.discriminator.save_weights(filepath + '_discriminator.weights.h5', overwrite=overwrite)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        with open(filepath + '_config.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        model = cls.from_config(config['config'])\n",
    "        model.generator.load_weights(filepath + '_generator.weights.h5')\n",
    "        model.discriminator.load_weights(filepath + '_discriminator.weights.h5')\n",
    "        return model\n",
    "\n",
    "# Instantiate and compile the ConditionalGAN model\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# Fit the model to the dataset\n",
    "cond_gan.fit(dataset, epochs=3)\n",
    "\n",
    "# Save the model\n",
    "cond_gan.save('cond_gan_model')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = ConditionalGAN.load('cond_gan_model')\n",
    "\n",
    "# Recompile the model after loading\n",
    "loaded_model.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# Verify the model structure\n",
    "print(loaded_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
