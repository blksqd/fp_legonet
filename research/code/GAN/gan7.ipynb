{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (4.41.2)\n",
      "Requirement already satisfied: diffusers in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.29.0)\n",
      "Requirement already satisfied: huggingface_hub in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.23.3)\n",
      "Requirement already satisfied: datasets in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (2.19.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (8.1.3)\n",
      "Requirement already satisfied: accelerate in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.31.0)\n",
      "Requirement already satisfied: torchvision in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: importlib-metadata in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from diffusers) (7.1.0)\n",
      "Requirement already satisfied: Pillow in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipywidgets) (8.23.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: psutil in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: sympy in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: decorator in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from importlib-metadata->diffusers) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers diffusers huggingface_hub datasets ipywidgets accelerate torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (10015, 128, 96, 3)\n",
      "Shape of labels: (10015, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181af880f47f457884d1a2968dc142ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d37fa438aff40bb9a66ade5b09905a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b5287d82fb406683ed4f2dcf9fd648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:  43%|####3     | 1.48G/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762b477474c3477fa6e43b871956fc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Load the Stable Diffusion model from Hugging Face\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionPipeline\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m pipe\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \u001b[39m# Use GPU for faster generation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Function to generate synthetic images using existing dataset images as references\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/gan7.ipynb#W1sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_synthetic_images\u001b[39m(images, labels, num_images):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/diffusers/pipelines/pipeline_utils.py:431\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    428\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been loaded in 8bit and moving it to \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     module\u001b[39m.\u001b[39;49mto(device, dtype)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    434\u001b[0m     module\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16\n\u001b[1;32m    435\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mstr\u001b[39m(device) \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    436\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    437\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    438\u001b[0m ):\n\u001b[1;32m    439\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[39m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[39m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m   1160\u001b[0m         device,\n\u001b[1;32m   1161\u001b[0m         dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1162\u001b[0m         non_blocking,\n\u001b[1;32m   1163\u001b[0m     )\n\u001b[1;32m   1164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot copy out of meta tensor; no data!\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers.models.modeling_outputs import Transformer2DModelOutput\n",
    "from huggingface_hub import login\n",
    "from PIL import Image\n",
    "\n",
    "# Configurations\n",
    "batch_size = 64\n",
    "num_channels = 3  # RGB images have 3 channels\n",
    "num_classes = 2\n",
    "image_size = (128, 96)  # Resize to save memory\n",
    "latent_dim = 128\n",
    "\n",
    "# Paths to data\n",
    "image_dir = '../FP/Data/HAM/ham_images'  # Directory containing images\n",
    "csv_path = '../FP/Experiments/two_class_metadata.csv'  # Path to CSV file\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract image IDs and classes\n",
    "image_ids = df['image_id'].values\n",
    "labels = df['class'].values\n",
    "\n",
    "# Encode labels to integers then to one-hot\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(integer_encoded, num_classes=num_classes)\n",
    "\n",
    "# Define function to get full image path\n",
    "def get_image_path(image_id):\n",
    "    return f\"{image_dir}/{image_id}.jpg\"\n",
    "\n",
    "# Load and process images\n",
    "def process_image(image_id):\n",
    "    full_path = get_image_path(image_id)\n",
    "    img = load_img(full_path, target_size=image_size, color_mode='rgb')  # Load as RGB\n",
    "    img_array = img_to_array(img).astype(\"float32\") / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Create datasets\n",
    "all_images = np.array([process_image(image_id) for image_id in image_ids])\n",
    "all_labels = one_hot_labels\n",
    "\n",
    "# Ensure the images have 4 dimensions (batch_size, height, width, channels)\n",
    "all_images = np.reshape(all_images, (-1, image_size[0], image_size[1], num_channels))\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Print data shapes for confirmation\n",
    "print(f\"Shape of images: {all_images.shape}\")\n",
    "print(f\"Shape of labels: {all_labels.shape}\")\n",
    "\n",
    "# Login to Hugging Face to access the model\n",
    "login()  # You will be prompted to enter your Hugging Face API token\n",
    "\n",
    "# Load the Stable Diffusion model from Hugging Face\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "pipe.to(\"cuda\")  # Use GPU for faster generation\n",
    "\n",
    "# Function to generate synthetic images using existing dataset images as references\n",
    "def generate_synthetic_images(images, labels, num_images):\n",
    "    synthetic_images = []\n",
    "    for i in range(num_images):\n",
    "        label_text = \"Benign\" if np.argmax(labels[i]) == 0 else \"Malignant\"\n",
    "        prompt = f\"{label_text} skin lesion\"\n",
    "\n",
    "        # Use the existing image as a reference\n",
    "        ref_image = Image.fromarray((images[i] * 255).astype(np.uint8))\n",
    "        ref_image = ref_image.resize((512, 512))\n",
    "\n",
    "        # Generate synthetic image based on prompt and reference image\n",
    "        generated_image = pipe(prompt, ref_image).images[0]\n",
    "        generated_image = generated_image.resize(image_size)  # Resize to the required image size\n",
    "        generated_image = np.array(generated_image) / 255.0  # Normalize the image\n",
    "\n",
    "        synthetic_images.append(generated_image)\n",
    "    return np.array(synthetic_images)\n",
    "\n",
    "# Example usage: Generate 10 synthetic images using reference images\n",
    "num_synthetic_images = 10\n",
    "synthetic_images = generate_synthetic_images(all_images[:num_synthetic_images], all_labels[:num_synthetic_images], num_synthetic_images)\n",
    "\n",
    "# Convert synthetic images to a tf.data.Dataset\n",
    "synthetic_dataset = tf.data.Dataset.from_tensor_slices((synthetic_images, all_labels[:num_synthetic_images]))\n",
    "synthetic_dataset = synthetic_dataset.batch(batch_size)\n",
    "\n",
    "# Function to save synthetic images\n",
    "def save_synthetic_images(images, save_dir):\n",
    "    import os\n",
    "    from PIL import Image\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for i, img in enumerate(images):\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        img.save(os.path.join(save_dir, f\"synthetic_image_{i}.png\"))\n",
    "\n",
    "# Save generated synthetic images\n",
    "save_synthetic_images(synthetic_images, \"./synthetic_images\")\n",
    "\n",
    "# Verify the synthetic dataset\n",
    "for images, labels in synthetic_dataset.take(1):\n",
    "    print(f\"Synthetic images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
