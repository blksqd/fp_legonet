{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation from the Keras example\n",
    "### Many parts of the code are carried over (re use maybe later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: pandas in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from matplotlib) (10.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/andreshofmann/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Downloading matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.4/232.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.0-cp38-cp38-macosx_11_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.5-cp38-cp38-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, pyparsing, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.53.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.7.5 pyparsing-3.1.2 scikit-learn-1.3.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "# from keras import ops\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "# from tensorflow_docs.vis import embed\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "batch_size = 64\n",
    "num_channels = 3  # RGB images have 3 channels\n",
    "num_classes = 2\n",
    "image_size = (128, 96)  # Resize to save memory\n",
    "latent_dim = 128\n",
    "\n",
    "# Paths to data\n",
    "image_dir = '../Data/HAM/ham_images'  # Directory containing images\n",
    "csv_path = '../Experiments/two_class_metadata.csv'  # Path to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract image IDs and classes\n",
    "image_ids = df['image_id'].values\n",
    "labels = df['class'].values\n",
    "\n",
    "# Encode labels to integers then to one-hot\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "one_hot_labels = to_categorical(integer_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get full image path\n",
    "def get_image_path(image_id):\n",
    "    return f\"{image_dir}/{image_id}.jpg\" \n",
    "\n",
    "# Load and process images\n",
    "def process_image(image_id):\n",
    "    full_path = get_image_path(image_id)\n",
    "    img = load_img(full_path, target_size=image_size, color_mode='rgb')  # Load as RGB\n",
    "    img_array = img_to_array(img).astype(\"float32\") / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (10015, 128, 96, 3)\n",
      "Shape of labels: (10015, 2)\n",
      "Generator input channels: 130\n",
      "Discriminator input channels: 5\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "all_images = np.array([process_image(image_id) for image_id in image_ids])\n",
    "all_labels = one_hot_labels\n",
    "\n",
    "# Ensure the images have 4 dimensions (batch_size, height, width, channels)\n",
    "# RGB images already have 3 channels, no need for additional dimension\n",
    "all_images = np.reshape(all_images, (-1, image_size[0], image_size[1], num_channels))\n",
    "\n",
    "# Create tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Print data shapes for confirmation\n",
    "print(f\"Shape of images: {all_images.shape}\")\n",
    "print(f\"Shape of labels: {all_labels.shape}\")\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "\n",
    "print(f\"Generator input channels: {generator_in_channels}\")\n",
    "print(f\"Discriminator input channels: {discriminator_in_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'negative_slope')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create the discriminator.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m discriminator \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInputLayer((\u001b[39m*\u001b[39mimage_size, discriminator_in_channels)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         layers\u001b[39m.\u001b[39mConv2D(\u001b[39m64\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         layers\u001b[39m.\u001b[39;49mLeakyReLU(negative_slope\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         layers\u001b[39m.\u001b[39mConv2D(\u001b[39m128\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         layers\u001b[39m.\u001b[39mLeakyReLU(negative_slope\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         layers\u001b[39m.\u001b[39mGlobalMaxPooling2D(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdiscriminator\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Create the generator.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m generator \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInputLayer((generator_in_channels,)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/GAN/gan2.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages/keras/src/layers/activation/leaky_relu.py:62\u001b[0m, in \u001b[0;36mLeakyReLU.__init__\u001b[0;34m(self, alpha, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 62\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe alpha value of a Leaky ReLU layer cannot be None, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpecting a float. Received: \u001b[39m\u001b[39m{\u001b[39;00malpha\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages/keras/src/engine/base_layer.py:340\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m allowed_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_dim\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimplementation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m }\n\u001b[1;32m    339\u001b[0m \u001b[39m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m generic_utils\u001b[39m.\u001b[39;49mvalidate_kwargs(kwargs, allowed_kwargs)\n\u001b[1;32m    342\u001b[0m \u001b[39m# Mutable properties\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    346\u001b[0m     \u001b[39misinstance\u001b[39m(trainable, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    347\u001b[0m     \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/Studies/Uol/7t/FP/.venv/lib/python3.8/site-packages/keras/src/utils/generic_utils.py:514\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mfor\u001b[39;00m kwarg \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m kwarg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m--> 514\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'negative_slope')"
     ]
    }
   ],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((*image_size, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense((image_size[0] // 4) * (image_size[1] // 4) * generator_in_channels),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((image_size[0] // 4, image_size[1] // 4, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(num_channels, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed = 1337\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "        print(f\"Real images shape: {real_images.shape}\")\n",
    "        print(f\"One-hot labels shape: {one_hot_labels.shape}\")\n",
    "\n",
    "        # Ensure one_hot_labels is float32\n",
    "        one_hot_labels = tf.cast(one_hot_labels, tf.float32)\n",
    "        \n",
    "        # Expand labels to match the shape of images for concatenation.\n",
    "        image_one_hot_labels = tf.reshape(one_hot_labels, (-1, 1, 1, num_classes))\n",
    "        image_one_hot_labels = tf.tile(image_one_hot_labels, [1, image_size[0], image_size[1], 1])\n",
    "        print(f\"Image one-hot labels shape: {image_one_hot_labels.shape}\")\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed)\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "        print(f\"Random latent vectors shape: {random_latent_vectors.shape}\")\n",
    "        print(f\"Random vector labels shape: {random_vector_labels.shape}\")\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "        print(f\"Generated images shape: {generated_images.shape}\")\n",
    "\n",
    "        # Ensure image_one_hot_labels is float32\n",
    "        image_one_hot_labels = tf.cast(image_one_hot_labels, tf.float32)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], axis=-1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], axis=-1)\n",
    "        combined_images = tf.concat([fake_image_and_labels, real_image_and_labels], axis=0)\n",
    "        print(f\"Combined images shape: {combined_images.shape}\")\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        print(f\"Discriminator labels shape: {labels.shape}\")\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            print(f\"Discriminator predictions shape: {predictions.shape}\")\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), seed=self.seed)\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        print(f\"Generator misleading labels shape: {misleading_labels.shape}\")\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], axis=-1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the ConditionalGAN model as before\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Real images shape: (None, 128, 96, 3)\n",
      "One-hot labels shape: (None, 2)\n",
      "Image one-hot labels shape: (None, 128, 96, 2)\n",
      "Random latent vectors shape: (None, 128)\n",
      "Random vector labels shape: (None, 130)\n",
      "Generated images shape: (None, 128, 96, 3)\n",
      "Combined images shape: (None, 128, 96, 5)\n",
      "Discriminator labels shape: (None, 1)\n",
      "Discriminator predictions shape: (None, 1)\n",
      "Generator misleading labels shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
