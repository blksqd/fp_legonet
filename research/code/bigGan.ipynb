{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: torch in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: sympy in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pytorch-pretrained-biggan in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (0.1.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pytorch-pretrained-biggan) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pytorch-pretrained-biggan) (1.26.4)\n",
      "Requirement already satisfied: boto3 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pytorch-pretrained-biggan) (1.34.144)\n",
      "Requirement already satisfied: requests in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pytorch-pretrained-biggan) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from pytorch-pretrained-biggan) (4.66.4)\n",
      "Requirement already satisfied: filelock in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from torch>=0.4.1->pytorch-pretrained-biggan) (2024.3.1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.144 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from boto3->pytorch-pretrained-biggan) (1.34.144)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from boto3->pytorch-pretrained-biggan) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from boto3->pytorch-pretrained-biggan) (0.10.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->pytorch-pretrained-biggan) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->pytorch-pretrained-biggan) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->pytorch-pretrained-biggan) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from requests->pytorch-pretrained-biggan) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.144->boto3->pytorch-pretrained-biggan) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-biggan) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from sympy->torch>=0.4.1->pytorch-pretrained-biggan) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.144->boto3->pytorch-pretrained-biggan) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow torch torchvision\n",
    "!pip install pytorch-pretrained-biggan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_pretrained_biggan import (\n",
    "    BigGAN,\n",
    "    one_hot_from_names,\n",
    "    truncated_noise_sample,\n",
    "    save_as_images,\n",
    "    display_in_terminal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_melanoma_dataset(data_dir, batch_size=32, image_size=64):\n",
    "    # Define the image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),  # Resize to 64x64\n",
    "        transforms.ToTensor(),  # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "# Usage\n",
    "data_dir = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/Images/img_patches/mel_patches'\n",
    "dataset = load_melanoma_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 557/557 [12:01:19<00:00, 77.70s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Average Loss: 0.1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:  19%|█▊        | 104/557 [1:33:00<6:51:18, 54.48s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x35217a3e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/andreshofmann/.pyenv/versions/3.12.2/envs/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1437, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/andreshofmann/.pyenv/versions/3.12.2/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andreshofmann/.pyenv/versions/3.12.2/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.UnpicklingError: pickle data was truncated\n",
      "Epoch 2/100:  35%|███▌      | 197/557 [3:03:55<5:29:54, 54.98s/it]  "
     ]
    }
   ],
   "source": [
    "# data loading function\n",
    "def load_melanoma_dataset(data_dir, batch_size=32, image_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    return dataloader\n",
    "\n",
    "def fine_tune_biggan(model, dataset, num_epochs=100, learning_rate=1e-4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Get the correct dimensions\n",
    "    noise_dim = model.config.z_dim\n",
    "    num_classes = model.config.num_classes\n",
    "\n",
    "    # List to store average loss for each epoch\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch, _ in tqdm(dataset, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            batch = batch.to(device)\n",
    "            batch_size = batch.size(0)\n",
    "\n",
    "            # Generate random noise\n",
    "            noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "            \n",
    "            # Generate random class labels\n",
    "            class_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "            \n",
    "            # Convert class labels to one-hot encoding\n",
    "            class_labels_one_hot = F.one_hot(class_labels, num_classes=num_classes).float()\n",
    "            \n",
    "            # Generate fake images\n",
    "            fake_images = model(noise, class_labels_one_hot, truncation=0.4)\n",
    "            \n",
    "            # Resize fake images to match your dataset (64x64)\n",
    "            fake_images = F.interpolate(fake_images, size=(64, 64), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(fake_images, batch)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "# Load your dataset\n",
    "data_dir = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/Images/img_patches/mel_patches'  \n",
    "dataset = load_melanoma_dataset(data_dir)\n",
    "\n",
    "# Load pre-trained BigGAN\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tuned_model, training_losses = fine_tune_biggan(model, dataset, num_epochs=100, learning_rate=1e-4)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(fine_tuned_model.state_dict(), 'fine_tuned_biggan.pth')\n",
    "print(\"Fine-tuned model saved as 'fine_tuned_biggan.pth'\")\n",
    "\n",
    "# Plot the training losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(training_losses) + 1), training_losses)\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.grid(True)\n",
    "plt.savefig('training_loss_plot.png')\n",
    "plt.show()\n",
    "print(\"Training loss plot saved as 'training_loss_plot.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_pretrained_biggan import BigGAN\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_melanoma_dataset(data_dir, batch_size=32, image_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, persistent_workers=False)\n",
    "    return dataloader\n",
    "\n",
    "def fine_tune_biggan(model, dataset, num_epochs=100, learning_rate=1e-4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    noise_dim = model.config.z_dim\n",
    "    num_classes = model.config.num_classes\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataset, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, _ = batch  # Assuming the dataset returns (images, labels), and we only need images here\n",
    "            images = images.to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "            class_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "            class_labels_one_hot = F.one_hot(class_labels, num_classes=num_classes).float()\n",
    "\n",
    "            fake_images = model(noise, class_labels_one_hot, truncation=0.4)\n",
    "            fake_images = F.interpolate(fake_images, size=(64, 64), mode='bilinear', align_corners=False)\n",
    "\n",
    "            loss = criterion(fake_images, images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import multiprocessing\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "    data_dir = '/Users/andreshofmann/Desktop/Studies/Uol/7t/FP/stage_2/Images/img_patches/mel_patches'\n",
    "    dataset = load_melanoma_dataset(data_dir)\n",
    "\n",
    "    model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "    fine_tuned_model, training_losses = fine_tune_biggan(model, dataset, num_epochs=100, learning_rate=1e-4)\n",
    "\n",
    "    torch.save(fine_tuned_model.state_dict(), 'fine_tuned_biggan.pth')\n",
    "    print(\"Fine-tuned model saved as 'fine_tuned_biggan.pth'\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(training_losses) + 1), training_losses)\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    plt.show()\n",
    "    print(\"Training loss plot saved as 'training_loss_plot.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
